# The Scalar Product

Euclidean geometry deals with concepts such as lines, circles, and perpendicularity. To arrive al Euclidean geometry, we need only add two more concepts to our vector space. These are distances between points, which allow as to define a circle, and angles between vectors so that would can say that two lines are perpendicular. The scalar product we introduce now will achieve both these goals.

Given any two vectors $a, \;b$, the scalar product $a \cdot b$ is a rule for obtaining a number with the following properties:
1. $a \cdot b= b \cdot a$
2. $a \cdot(\lambda b)= \lambda (a \cdot b)$
3. $a \cdot (b + c)= a \cdot b + a \cdot c$
4. $a \cdot a > 0$, unless $a = 0.$
Property 4 will be relaxed when we study relativity. With the introduction of the scalar product, we can now define the length of a vector, $|a|$, by

$$|a|=  \sqrt{a \cdot a}$$

Throughout the book we will assume the positive square root is always implied by the $\sqrt{}$ symbol. The fact that we now have a definition of lengths and distances means that we have specified a *metric space*. Many different types of metric spaces can be constructed, of which the simplest are the Euclidean spaces we have just defined.

The fact that for Euclidean space the inner product is positive definite means that we have a Schwarz inequality of the form

$$|a \cdot b| \leq|a||b|.$$

We can now define the *angle* $\theta$ between a and b by

$$a \cdot b =|a||b|\cos (\theta).$$

Two vectors are said to be *orthogonal* if their scalar product is zero. It is usually convenient work with basis in which all the vectors are mutually orthogonal. If all of the basis vectors are further normalized to have unit length, they are said to form an *orthonormal basis* . If the set of vectors $\{\mathsf{e_{1}},...,\mathsf{e_{n}}\}$ denote such a basis, the statement that the basis is  orthonormal can be summarized as

$$\mathsf{e_{i}\cdot e_{j}}= \delta_{ij}.$$

Where $\delta_{ij}$ is the  Kronecker delta function, defined by

$$\delta_{ij}=
\begin{cases}
1 \quad \text{if} \quad i = j ,\\[1em]
0 \quad \text{if}\quad i \neq j.
\end{cases}
$$

We request expand any vector $a$ in this basis as

$$a = \sum\limits_{i = 1}^{n}a_{i}\mathsf{e_{i}=}a_{i}\mathsf{e_{i}},$$

Where we have started to employ the *Einstein summation notation* that pairs of indices in any expression are summed over. This convention will be assumed throughout this book. The $\{a_{i}\}$ are the *components* of the vector $a$ in the $\{\mathsf{e_{i}}\}$basis. These are found simply by

$$a_{i}= \mathsf{e_{i}}\cdot a.$$

The scalar product of two vectors $a = a_{i}\mathsf{e_{i}}$ and $b = b_{i}\mathsf{e_{i}}$ can now be simply be written as

$$a \cdot b = (a_{i}\mathsf{e_{i}})\cdot (b_{j}\mathsf{e_{j}})= a_{i}b_{j}\mathsf{e_{i}\cdot e_{j}}= a_{i}b_{j}\delta_{ij}= a_{i}b_{j}.$$

In spaces where the inner product is not positive-definite, such as Minkowski spacetime, there is no equivalent version of the Schwarz inequality. In such cases it is often only possible to define an "angle" between vectors by replacing the cosine function with a cosh function. In these cases we can still introduce orthonormal frames and use these to compute scalar products. The main modification is that the Kronecker delta is replaced by $\eta_{ij}$ by again is zero if $i \neq j$ but also admits values $\pm1$ if $i = j$.